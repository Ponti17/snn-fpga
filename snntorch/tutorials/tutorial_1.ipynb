{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# snntorch - Tutorial 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spiking Neural Network\n",
    "import snntorch as snn\n",
    "from snntorch import utils\n",
    "from snntorch import spikegen\n",
    "\n",
    "# Torch\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Torchvision\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import snntorch.spikeplot as splt\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Parameters\n",
    "batch_size=128\n",
    "data_path='/tmp/data/mnist'\n",
    "num_classes = 10  # MNIST has 10 output classes\n",
    "\n",
    "# Torch Variables\n",
    "dtype = torch.float\n",
    "\n",
    "# Define a transform\n",
    "transform = transforms.Compose([\n",
    "            transforms.Resize((28,28)),\n",
    "            transforms.Grayscale(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0,), (1,))])\n",
    "\n",
    "mnist_train = datasets.MNIST(data_path, train=True, download=True, transform=transform)\n",
    "subset = 10\n",
    "mnist_train = utils.data_subset(mnist_train, subset)\n",
    "print(f\"The size of mnist_train is {len(mnist_train)}\")\n",
    "\n",
    "train_loader = DataLoader(mnist_train, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create raw vectors\n",
    "raw_vector_10 = torch.ones(10)*0.5\n",
    "raw_vector_100 = torch.ones(100)*0.5\n",
    "\n",
    "# pass each sample through a Bernoulli trial\n",
    "rate_coded_vector_10 = torch.bernoulli(raw_vector_10)\n",
    "rate_coded_vector_100 = torch.bernoulli(raw_vector_100)\n",
    "\n",
    "print(f\"The output is spiking {rate_coded_vector_10.sum()*100/len(rate_coded_vector_10):.2f}% of the time.\")\n",
    "print(f\"The output is spiking {rate_coded_vector_100.sum()*100/len(rate_coded_vector_100):.2f}% of the time.\")\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(15, 5))\n",
    "ax[0].bar(range(10), rate_coded_vector_10)\n",
    "ax[0].set_title(\"Rate coded vector with 10 elements\")\n",
    "ax[1].bar(range(100), rate_coded_vector_100)\n",
    "ax[1].set_title(\"Rate coded vector with 100 elements\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### spikegen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_steps = 100\n",
    "\n",
    "# Iterate through minibatches\n",
    "data = iter(train_loader)\n",
    "data_it, targets_it = next(data)\n",
    "\n",
    "# Spiking Data\n",
    "spike_data = spikegen.rate(data_it, num_steps=num_steps)\n",
    "print(spike_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take sample and animate\n",
    "spike_data_sample = spike_data[:, 0, 0]\n",
    "print(spike_data_sample.size())\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "print(f\"The corresponding target is: {targets_it[0]}\")\n",
    "anim = splt.animator(spike_data_sample, fig, ax)\n",
    "video = HTML(anim.to_html5_video())\n",
    "plt.close()\n",
    "video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can reduce the spimking frequency by reducing the gain\n",
    "spike_data = spikegen.rate(data_it, num_steps=num_steps, gain=0.25)\n",
    "\n",
    "spike_data_sample2 = spike_data[:, 0, 0]\n",
    "fig, ax = plt.subplots()\n",
    "print(f\"The corresponding target is: {targets_it[0]}\")\n",
    "anim = splt.animator(spike_data_sample2, fig, ax)\n",
    "video = HTML(anim.to_html5_video())\n",
    "plt.close()\n",
    "video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can average the spikes out over time\n",
    "plt.figure(facecolor=\"w\")\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(spike_data_sample.mean(axis=0).reshape((28,-1)).cpu(), cmap='binary')\n",
    "plt.axis('off')\n",
    "plt.title('Gain = 1')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(spike_data_sample2.mean(axis=0).reshape((28,-1)).cpu(), cmap='binary')\n",
    "plt.axis('off')\n",
    "plt.title('Gain = 0.25')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raster Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape\n",
    "spike_data_sample2 = spike_data_sample2.reshape((num_steps, -1))\n",
    "\n",
    "# raster plot\n",
    "fig = plt.figure(facecolor=\"w\", figsize=(10, 5))\n",
    "ax = fig.add_subplot(111)\n",
    "splt.raster(spike_data_sample2, ax, s=1.5, c=\"black\")\n",
    "\n",
    "plt.title(\"Input Layer\")\n",
    "plt.xlabel(\"Time step\")\n",
    "plt.ylabel(\"Neuron Number\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 210  # index into 210th neuron\n",
    "\n",
    "fig = plt.figure(facecolor=\"w\", figsize=(8, 1))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "splt.raster(spike_data_sample.reshape(num_steps, -1)[:, idx].unsqueeze(1), ax, s=100, c=\"black\", marker=\"|\")\n",
    "\n",
    "plt.title(\"Input Neuron\")\n",
    "plt.xlabel(\"Time step\")\n",
    "plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latency Coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_time(data, tau=5, threshold=0.01):\n",
    "    spike_time = tau * torch.log(data / (data - threshold))\n",
    "    return spike_time\n",
    "\n",
    "raw_input = torch.arange(0, 5, 0.05) # tensor from 0 to 5\n",
    "spike_times = convert_to_time(raw_input)\n",
    "\n",
    "plt.plot(raw_input, spike_times)\n",
    "plt.xlabel('Input Value')\n",
    "plt.ylabel('Spike Time (s)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_data = spikegen.latency(data_it, num_steps=100, tau=5, threshold=0.01)\n",
    "\n",
    "# Raster Plot\n",
    "fig = plt.figure(facecolor=\"w\", figsize=(10, 5))\n",
    "ax = fig.add_subplot(111)\n",
    "splt.raster(spike_data[:, 0].view(num_steps, -1), ax, s=25, c=\"black\")\n",
    "\n",
    "plt.title(\"Input Layer\")\n",
    "plt.xlabel(\"Time step\")\n",
    "plt.ylabel(\"Neuron Number\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Due to the lack of midtone/grayscale features there is significant clustering.\n",
    "# Tau can be icnreased or the spike times can be linearized.\n",
    "spike_data = spikegen.latency(data_it, num_steps=100, tau=5, threshold=0.01, linear=True)\n",
    "\n",
    "fig = plt.figure(facecolor=\"w\", figsize=(10, 5))\n",
    "ax = fig.add_subplot(111)\n",
    "splt.raster(spike_data[:, 0].view(num_steps, -1), ax, s=25, c=\"black\")\n",
    "plt.title(\"Input Layer\")\n",
    "plt.xlabel(\"Time step\")\n",
    "plt.ylabel(\"Neuron Number\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All the firing occurs in the first 5 time steps, whereas the simulation is 100 time steps.\n",
    "# We can increase Tau or normalize to the full span of num_steps\n",
    "spike_data = spikegen.latency(data_it, num_steps=100, tau=5, threshold=0.01,\n",
    "                              normalize=True, linear=True)\n",
    "\n",
    "fig = plt.figure(facecolor=\"w\", figsize=(10, 5))\n",
    "ax = fig.add_subplot(111)\n",
    "splt.raster(spike_data[:, 0].view(num_steps, -1), ax, s=25, c=\"black\")\n",
    "\n",
    "plt.title(\"Input Layer\")\n",
    "plt.xlabel(\"Time step\")\n",
    "plt.ylabel(\"Neuron Number\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All the neurons firing at the end is the black background of MNIST.\n",
    "# It contains no useful information and can be removed with clipping.\n",
    "spike_data = spikegen.latency(data_it, num_steps=100, tau=5, threshold=0.01,\n",
    "                              clip=True, normalize=True, linear=True)\n",
    "\n",
    "fig = plt.figure(facecolor=\"w\", figsize=(10, 5))\n",
    "ax = fig.add_subplot(111)\n",
    "splt.raster(spike_data[:, 0].view(num_steps, -1), ax, s=25, c=\"black\")\n",
    "\n",
    "plt.title(\"Input Layer\")\n",
    "plt.xlabel(\"Time step\")\n",
    "plt.ylabel(\"Neuron Number\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_data_sample = spike_data[:, 0, 0]\n",
    "fig, ax = plt.subplots()\n",
    "print(f\"The corresponding target is: {targets_it[0]}\")\n",
    "anim = splt.animator(spike_data_sample, fig, ax)\n",
    "video = HTML(anim.to_html5_video())\n",
    "plt.close()\n",
    "video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delta Modulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a tensor with some fake time-series data\n",
    "data = torch.Tensor([0, 1, 0, 2, 8, -20, 20, -5, 0, 1, 0])\n",
    "\n",
    "# Plot the tensor\n",
    "plt.plot(data)\n",
    "\n",
    "plt.title(\"Some fake time-series data\")\n",
    "plt.xlabel(\"Time step\")\n",
    "plt.ylabel(\"Voltage (mV)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data\n",
    "spike_data = spikegen.delta(data, threshold=4)\n",
    "\n",
    "# Create fig, ax\n",
    "fig = plt.figure(facecolor=\"w\", figsize=(8, 1))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "# Raster plot of delta converted data\n",
    "splt.raster(spike_data, ax, c=\"black\")\n",
    "\n",
    "plt.title(\"Input Neuron\")\n",
    "plt.xlabel(\"Time step\")\n",
    "plt.yticks([])\n",
    "plt.xlim(0, len(data))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data\n",
    "spike_data = spikegen.delta(data, threshold=4, off_spike=True)\n",
    "\n",
    "# Create fig, ax\n",
    "fig = plt.figure(facecolor=\"w\", figsize=(8, 1))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "# Raster plot of delta converted data\n",
    "splt.raster(spike_data, ax, c=\"black\")\n",
    "\n",
    "plt.title(\"Input Neuron\")\n",
    "plt.xlabel(\"Time step\")\n",
    "plt.yticks([])\n",
    "plt.xlim(0, len(data))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
