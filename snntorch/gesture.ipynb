{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test of SNN for Gesture Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SNN\n",
    "import tonic\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML\n",
    "\n",
    "# Misc\n",
    "import numpy as np\n",
    "import numpy.lib.recfunctions as rf\n",
    "\n",
    "# Core\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset Using Tonic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the path to this file and create a data directory\n",
    "data_path = os.path.join(os.getcwd(), \"data\")\n",
    "os.makedirs(data_path, exist_ok=True)\n",
    "\n",
    "# Load the dataset using Tonic\n",
    "train = tonic.datasets.DVSGesture(save_to=data_path, train=True)\n",
    "test = tonic.datasets.DVSGesture(save_to=data_path, train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Event Extraction\n",
    "\n",
    "Each set in the dataset contains a series of `events`. An event consists of a XY-coordinate that either increased or decreases in intensity depending on the polarity. The timestamps are the time the event occured in ms.\n",
    "\n",
    "### Labels\n",
    "For some reason the labels from the dataset csv are _not_ zero-indexed. Beware.\n",
    "\n",
    "- **1**: hand_clapping\n",
    "- **2**: right_hand_wave\n",
    "- **3**: left_hand_wave\n",
    "- **4**: right_hand_clockwise\n",
    "- **5**: right_hand_counter_clockwise\n",
    "- **6**: left_hand_clockwise\n",
    "- **7**: left_hand_counter_clockwise\n",
    "- **8**: forearm_roll_forward\n",
    "- **8**: forearm_roll_backward\n",
    "- **9**: drums\n",
    "- **10**: guitar\n",
    "- **11**: random_other_gestures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events, label = train[0]\n",
    "\n",
    "timestamps = events['t']\n",
    "x_coords = events['x']\n",
    "y_coords = events['y']\n",
    "polarities = events['p']\n",
    "\n",
    "cut = 5\n",
    "print(\"Timestamps:\", timestamps[:cut])\n",
    "print(\"X-coordinates:\", x_coords[:cut])\n",
    "print(\"Y-coordinates:\", y_coords[:cut])\n",
    "print(\"Polarities:\", polarities[:cut])\n",
    "print(\"Label:\", label+1) # +1 because the labels are 0-indexed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accumulate All Events and Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_size = (128, 128)  # Assuming a 64x128 sensor\n",
    "\n",
    "# Create empty images for ON and OFF events\n",
    "on_event_image = np.zeros(sensor_size)\n",
    "off_event_image = np.zeros(sensor_size)\n",
    "\n",
    "num_events = 10000\n",
    "for i in range(num_events):\n",
    "    x, y, p = x_coords[i], y_coords[i], polarities[i]\n",
    "    if p:\n",
    "        on_event_image[y, x] += 1\n",
    "    else:\n",
    "        off_event_image[y, x] += 1\n",
    "\n",
    "# Plot the accumulated event frames\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "ax[0].imshow(on_event_image, cmap=\"Reds\")\n",
    "ax[0].set_title(\"ON Events\")\n",
    "\n",
    "ax[1].imshow(off_event_image, cmap=\"Blues\")\n",
    "ax[1].set_title(\"OFF Events\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Animation\n",
    "Bootleg way to animate the events.\n",
    "\n",
    "Events are binned by time and a frame is generated and saved in `./frames`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_us(seconds):\n",
    "    \"\"\"\n",
    "    Converts seconds to microseconds.\n",
    "    \"\"\"\n",
    "    return seconds * 1e6\n",
    "\n",
    "def create_frames_dir() -> str:\n",
    "    \"\"\"\n",
    "    Create the frames directory and clean it if it exists.\n",
    "    \"\"\"\n",
    "    data_path = os.path.join(os.getcwd(), \"frames\")\n",
    "    if os.path.exists(data_path):\n",
    "        for file in os.listdir(data_path):\n",
    "            file_path = os.path.join(data_path, file)\n",
    "            if os.path.isfile(file_path):\n",
    "                os.unlink(file_path)\n",
    "    else:\n",
    "        os.makedirs(data_path, exist_ok=True)\n",
    "    return data_path\n",
    "\n",
    "def time_bin_frames(events, sensor_size, time_bin) -> None:\n",
    "    \"\"\"\n",
    "    Accumulates events in time bins and saves them as frames.\n",
    "\n",
    "    Args:\n",
    "        events: The events dictionary.\n",
    "        time_bin: The time bin in microseconds.\n",
    "    \"\"\"\n",
    "    timestamps = events['t']\n",
    "    x_coords = events['x']\n",
    "    y_coords = events['y']\n",
    "    polarities = events['p']\n",
    "\n",
    "    frame_path = create_frames_dir()\n",
    "\n",
    "    on_event_image = np.zeros(sensor_size)\n",
    "    off_event_image = np.zeros(sensor_size)\n",
    "    time = time_bin\n",
    "    for i, (x, y, p) in enumerate(zip(x_coords, y_coords, polarities)):\n",
    "        on_event_image[y, x] += p\n",
    "        off_event_image[y, x] += 1 - p\n",
    "        if timestamps[i] >= time:\n",
    "            total_events = on_event_image + off_event_image\n",
    "            plt.imsave(os.path.join(frame_path, f\"frame_{time*1e-3}ms.png\"), total_events, cmap=\"Reds\")\n",
    "            on_event_image = np.zeros(sensor_size)\n",
    "            off_event_image = np.zeros(sensor_size)\n",
    "            time += time_bin\n",
    "\n",
    "def frames_to_video(time_bin, frame_dir=\"./frames\") -> HTML:\n",
    "    \"\"\"\n",
    "    Converts the frames to a video.\n",
    "    \"\"\"\n",
    "    frame_dir = \"./frames\"\n",
    "    # List images and sort them correctly. This is an absolutely disgusting solution.\n",
    "    images = sorted(\n",
    "        [image for image in os.listdir(frame_dir) if image.endswith(\".png\")],\n",
    "        key=lambda x: int(\"\".join(filter(str.isdigit, x)))\n",
    "    )\n",
    "    images = [os.path.join(frame_dir, image) for image in images]\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "    img = plt.imread(images[0])\n",
    "    im = ax.imshow(img, animated=True)\n",
    "\n",
    "    def update(frame):\n",
    "        im.set_array(plt.imread(images[frame]))\n",
    "        return [im]\n",
    "\n",
    "    anim = animation.FuncAnimation(fig, update, frames=len(images), interval=time_bin*1e-3, blit=True)\n",
    "    video = HTML(anim.to_html5_video())\n",
    "    plt.close()\n",
    "    return video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events, label = train[0]\n",
    "time_bin_frames(events, (128, 128), to_us(0.05))\n",
    "frames_to_video(to_us(0.05))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w, h = 32, 32\n",
    "n_frames = 32\n",
    "debug = False\n",
    "\n",
    "# Denoise: Removes outlier events with inactive surrounding pixels for 10ms\n",
    "# Downsample: Downsamples the image to 32x32\n",
    "# ToFrame: Converts the events to n_frames frames per trail\n",
    "transforms = tonic.transforms.Compose([\n",
    "    tonic.transforms.Denoise(filter_time=10000),\n",
    "    tonic.transforms.Downsample(sensor_size=tonic.datasets.DVSGesture.sensor_size, target_size=(w,h)),\n",
    "])\n",
    "\n",
    "data_path = os.path.join(os.getcwd(), \"data\")\n",
    "os.makedirs(data_path, exist_ok=True)\n",
    "\n",
    "train2 = tonic.datasets.DVSGesture(save_to=data_path, transform=transforms, train=True)\n",
    "test2 = tonic.datasets.DVSGesture(save_to=data_path, transform=transforms, train=False)\n",
    "\n",
    "cache_path = os.path.join(os.getcwd(), \"./data/cache\")\n",
    "os.makedirs(cache_path, exist_ok=True)\n",
    "cached_train = train2 if debug else tonic.DiskCachedDataset(train2, cache_path=cache_path)\n",
    "cached_test = test2 if debug else tonic.DiskCachedDataset(test2, cache_path=cache_path)\n",
    "\n",
    "events, label = cached_train[0]\n",
    "time_bin_frames(events, (w, h), to_us(0.05))\n",
    "frames_to_video(to_us(0.05))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
